Using diffdominion.sh to compare a classmate's dominion with mine, it was not exactly easy to decide whose is correct. Outputs seemed to be consistently different, and this is likely due to random testing. The random tests will create different values, meaning that the number of players and the card choices will differ. This is not an ideal case for differential testing because we do not have 100% correct dominion code to compare ours to, and without a working implementation, we cannot make productive conclusions when comparing the two outputs. It's especially difficult when outputs are different for the same seed. I ended up with around 65% coverage after 20 iterations of testdominion, and my classmate had about 68%, and neither is sufficient to discern whether one or the other is correct. 
